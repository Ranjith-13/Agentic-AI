# ğŸ§ª Test Case Generator Agent (Azure OpenAI)

An autonomous **AI-powered test case generation agent** that reads Python source code, analyzes its functions and behaviors, and produces:

* âœ”ï¸ A complete **test plan** (Markdown)
* âœ”ï¸ A fully runnable **pytest test file**
* âœ”ï¸ Follows strict JSON formatting rules
* âœ”ï¸ Uses Azure OpenAI for reasoning

This agent is ideal for:
* Automated QA
* Increasing test coverage
* Code reliability improvements
* Developers who want instant tests for new functions

---

## ğŸš€ What the Agent Does

For any Python file, the agent:

1. **Reads the file** (`file_tool.py`)
2. **Understands functions, parameters, edge cases**
3. **Generates a complete test plan** (Markdown)
4. **Generates a pytest test file** (unit + boundary + negative cases)
5. **Outputs valid JSON only** (strict validation)
6. **Automatically saves both files**

Output files:

* `sample_code.py_test_plan.md`
* `test_sample_code.py`

---

## ğŸ“ Project Structure

```
test-case-generator/
â”‚
â”œâ”€â”€ test_case_agent.py      # Core agent (LLM-powered test generation)
â”œâ”€â”€ main.py                 # Runner script
â”œâ”€â”€ file_tool.py            # File loading & saving
â”œâ”€â”€ utils.py                # Filename sanitizer
â”œâ”€â”€ sample_code.py          # Input example
â”œâ”€â”€ test_sample_code.py     # (Generated output)
â”œâ”€â”€ requirements.txt        # Dependencies
â””â”€â”€ README.md
```

---

## ğŸ§  How the Agent Works Internally

### 1ï¸âƒ£ Perception Layer â€” Reading Code

The agent loads the Python source file using `read_file`.

### 2ï¸âƒ£ Reasoning Layer â€” LLM Processing

LLM extracts:

* Function names
* Arguments
* Behaviors
* Conditions
* Failure modes
* Edge cases

### 3ï¸âƒ£ Planning Layer â€” Test Strategies

The agent plans:

* Positive tests
* Negative tests
* Boundary tests
* Error handling tests
* Mocking strategy (if applicable)

### 4ï¸âƒ£ Action Layer â€” JSON Response

Azure OpenAI must return **strict JSON**:

```
{
  "test_plan": "markdown content",
  "test_file": "pytest content"
}
```

The agent validates it using Python's `json` module.

### 5ï¸âƒ£ Tool Use â€” Saving Files

Files are automatically written using `save_text`.

---

## ğŸ”§ Installation & Setup

### 1ï¸âƒ£ Create and activate the virtual environment

```bash
python -m venv venv
source venv/bin/activate       # Mac/Linux
venv\Scripts\activate          # Windows
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Configure Azure OpenAI in `.env`

```
AZURE_OPENAI_API_KEY=your_key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-12-01-preview
AZURE_OPENAI_DEPLOYMENT=your_model_name
```

---

## â–¶ï¸ Running the Agent

To process `sample_code.py`:

```bash
python main.py sample_code.py
```

You will see:

```
â³ Generating test cases...
Saved â†’ sample_code.py_test_plan.md
Saved â†’ test_sample_code.py

âœ… Test Case Generation Complete!
```

Both output files will be available.

---

## ğŸ“Œ Why this use-case:

### âœ”ï¸ 1. **Agent Structure**

* LLM wrapper (`TestCaseGeneratorAgent`)
* Tools for reading/saving files
* Execution orchestrator (`main.py`)

### âœ”ï¸ 2. **Tool/API Interaction**

* Azure OpenAI (LLM)
* Local file system

### âœ”ï¸ 3. **Autonomous Task Completion**

The agent performs:

```
read â†’ analyze â†’ generate plan â†’ generate tests â†’ save â†’ done
```

Zero human intervention.

---

## ğŸ§ª Example Input Functions

From `sample_code.py`:

* `divide(a, b)`
* `is_valid_age(age)`
* `greet(name)`

The agent generates:

* Edge-case coverage
* Exception tests
* Type/validation tests

Example generated tests include:

```python
with pytest.raises(ZeroDivisionError):
    divide(10, 0)
```

---
